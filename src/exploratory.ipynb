{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning and NLP libraries\n",
    "#import torchtext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from gensim.matutils import corpus2dense, corpus2csc\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# other libraries\n",
    "import warnings\n",
    "\n",
    "# own modules\n",
    "from src.basic_project import preprocessing, extract_data, BasicModel\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels, costs, contributions = extract_data('data/projects.xlsx', 'data/SciVocCodes.xlsx')\n",
    "texts = preprocessing(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get texts in right format\n",
    "D = Dictionary([sentence.split(' ') for sentence in texts])\n",
    "n_tokens = len(D)\n",
    "reviews_bow = [D.doc2bow(doc.split(' ')) for doc in texts]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Vectorization Techniques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tfidf representations\n",
    "tfidf = TfidfModel(reviews_bow)\n",
    "reviews_tfidf = tfidf[reviews_bow]\n",
    "\n",
    "# create sparse corpus\n",
    "num_docs = len(reviews_bow)\n",
    "corpus_tfidf_sparse = corpus2csc(reviews_tfidf, num_terms=n_tokens, num_docs=num_docs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModel(corpus_tfidf_sparse, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy: {model.accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.classification_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros((len(texts), 300))\n",
    "glove = torchtext.vocab.GloVe(name='6B', dim=300)\n",
    "for i in range(len(texts)):\n",
    "    embeddings[i] = glove.get_vecs_by_tokens(texts[i].split(' '), lower_case_backup=True).mean(dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModel(embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6768857690045743\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {model.accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.82      0.68       488\n",
      "           1       0.81      0.52      0.63      1326\n",
      "           2       0.60      0.70      0.64       659\n",
      "           3       0.25      0.64      0.36        73\n",
      "           4       0.61      0.59      0.60       549\n",
      "           5       0.49      0.79      0.60       111\n",
      "\n",
      "    accuracy                           0.63      3206\n",
      "   macro avg       0.56      0.68      0.59      3206\n",
      "weighted avg       0.67      0.63      0.63      3206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.classification_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Vectorization Techniques with Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = normalize(np.expand_dims(costs, 1), axis=1)\n",
    "contributions = normalize(np.expand_dims(costs, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = hstack((corpus_tfidf_sparse, csr_matrix(costs), csr_matrix(contributions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModel(dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy: {model.accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.classification_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros((len(texts), 300))\n",
    "glove = torchtext.vocab.GloVe(name='6B', dim=300)\n",
    "for i in range(len(texts)):\n",
    "    embeddings[i] = glove.get_vecs_by_tokens(texts[i].split(' '), lower_case_backup=True).mean(dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate((embeddings, costs, contributions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModel(dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6770114603067362\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {model.accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.82      0.68       488\n",
      "           1       0.81      0.52      0.63      1326\n",
      "           2       0.60      0.70      0.64       659\n",
      "           3       0.25      0.64      0.36        73\n",
      "           4       0.61      0.59      0.60       549\n",
      "           5       0.49      0.79      0.60       111\n",
      "\n",
      "    accuracy                           0.63      3206\n",
      "   macro avg       0.56      0.68      0.59      3206\n",
      "weighted avg       0.67      0.63      0.63      3206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.classification_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ======== LDA MODEL ========"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute LDA model\n",
    "num_topics = 90\n",
    "ldag = LdaModel(corpus=reviews_bow, id2word=D, num_topics=num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sparse corpus\n",
    "corpus_ldag = ldag[reviews_bow]\n",
    "num_docs = len(reviews_bow)\n",
    "corpus_ldag_sparse = corpus2csc(corpus_ldag, num_terms=n_tokens, num_docs=num_docs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModel(corpus_ldag_sparse, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 63.94%\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {model.accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.81      0.67       488\n",
      "           1       0.78      0.50      0.61      1326\n",
      "           2       0.56      0.67      0.61       659\n",
      "           3       0.17      0.47      0.25        73\n",
      "           4       0.58      0.48      0.53       549\n",
      "           5       0.42      0.81      0.55       111\n",
      "\n",
      "    accuracy                           0.59      3206\n",
      "   macro avg       0.51      0.62      0.54      3206\n",
      "weighted avg       0.64      0.59      0.59      3206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.classification_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
